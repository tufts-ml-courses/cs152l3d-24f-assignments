{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1: Transfer Learning\n",
    "\n",
    "Tufts CS 152 L3D, Fall 2024\n",
    "\n",
    "Official Instructions: <https://www.cs.tufts.edu/cs/152L3D/2024f/hw1.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "This assignment might take a while.\n",
    "We recommend setting several variables here that prevent repeating long-running tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # TODO change to GPU if you have one (e.g. on Colab)\n",
    "\n",
    "PROB1_res_file = 'prob1_results.pkl'\n",
    "PROB2_res_file = 'prob2_results.pkl'\n",
    "PROB1_EXPERIMENTS = True  # Flag will skip re-running experiments if set to False\n",
    "PROB1_PLOTS = True\n",
    "PROB2_EXPERIMENTS = True\n",
    "PROB2_PLOTS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "\n",
    "**Option 1: Colab**\n",
    "To use this notebook with Google Colab, you will need an account and Google Drive storage (free tier just fine)\n",
    "\n",
    "Please be sure you are *logged in* and have given requisite permission to access Drive to Google Colab.\n",
    "\n",
    "The lines below will:\n",
    "\n",
    "* Make folders called `CS152L3D_2024f/HW1/` in your google drive\n",
    "* Clone the HW1 starter code repository there\n",
    "* Note: Colab expects *this notebook* (or any notebook) will be in `Colab Notebooks/`.\n",
    "\n",
    "That will let us use the starter code in this notebook.\n",
    "\n",
    "**Option 2: Local**\n",
    "\n",
    "You can also try to use your local machine (but if you don't have a GPU, this may be slow and painful.\n",
    "If you choose this route, the lines below specific to Colab will just be skipped, and nothing will be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    COLAB = True\n",
    "except ImportError:\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    if not os.path.exists(os.path.join('/content/drive/MyDrive/', 'CS152L3D_2024f')):\n",
    "        !cd /content/drive/MyDrive/ && mkdir CS152L3D_2024f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move notebook working directory into the folder\n",
    "if COLAB:\n",
    "    %cd /content/drive/MyDrive/CS152L3D_2024f/\n",
    "\n",
    "    # Clone the repo\n",
    "    if not os.path.exists('cs152l3d-24f-assignments/hw1/'):\n",
    "      !git clone https://github.com/tufts-ml-courses/cs152l3d-24f-assignments\n",
    "\n",
    "    # cd into repo\n",
    "    %cd cs152l3d-24f-assignments/hw1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for success. We should be able to see files like\n",
    "\n",
    "* model.py\n",
    "* data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                     hw1_template.tex\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                   l3d_24f_cpu.yml\r\n",
      "best_model.pth                l3d_24f_cuda.yml\r\n",
      "\u001b[34mbirdsnap10\u001b[m\u001b[m                    models.py\r\n",
      "birdsnap10_224x224only.zip    resnet10-1253-88a5961b.pth\r\n",
      "data_utils.py                 run_nb_with_clean_metadata.sh\r\n",
      "hw1.ipynb                     train.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    try:\n",
    "        import torchinfo\n",
    "        import pytorchcv\n",
    "    except ImportError:\n",
    "        rstr = '''\n",
    "            torchinfo\n",
    "            pytorchcv\n",
    "            '''\n",
    "        with open('colab_requirements.txt', 'w') as f:\n",
    "            f.write(rstr)\n",
    "        !pip install -r colab_requirements.txt\n",
    "        import torchinfo\n",
    "        import pytorchcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mhughes/courses/cs152l3d-24f-assignments/hw1/birdsnap10\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.environ.get('DATA_DIR', os.path.abspath('./birdsnap10'))\n",
    "print(DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_DIR):\n",
    "    !unzip birdsnap10_224x224only.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAmerican_Black_Duck\u001b[m\u001b[m \u001b[34mHarlequin_Duck\u001b[m\u001b[m      \u001b[34mPrairie_Falcon\u001b[m\u001b[m      \u001b[34mWhite_faced_Ibis\u001b[m\u001b[m\r\n",
      "\u001b[34mGolden_Eagle\u001b[m\u001b[m        \u001b[34mOsprey\u001b[m\u001b[m              \u001b[34mShort_eared_Owl\u001b[m\u001b[m\r\n",
      "\u001b[34mGreat_Horned_Owl\u001b[m\u001b[m    \u001b[34mPeregrine_Falcon\u001b[m\u001b[m    \u001b[34mWhite_Ibis\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "# Show contents of train set\n",
    "!ls $DATA_DIR/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import third-party library modules\n",
    "import json\n",
    "import pickle\n",
    "import itertools\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "import pytorchcv\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
    "sns.set('notebook', style='whitegrid', font_scale=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import starter code modules from local files\n",
    "\n",
    "Use **autoreload** so that any changes to these local files will be automatically reloaded into this nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utils from provided local starter code files\n",
    "import data_utils\n",
    "import models\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run this cell if you've made changes to your local file, but they aren't reflected in current nb kernel state\n",
    "import importlib\n",
    "importlib.reload(models);\n",
    "importlib.reload(train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show basic ResNet10 architecture\n",
    "\n",
    "Load ResNet10. All layers trainable by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Trainable parameter count=4910922 over 38 tensors in layers: features.init_block.conv.conv,features.init_block.conv.bn,features.stage1.unit1.body.conv1.conv,features.stage1.unit1.body.conv1.bn,features.stage1.unit1.body.conv2.conv,features.stage1.unit1.body.conv2.bn,features.stage2.unit1.body.conv1.conv,features.stage2.unit1.body.conv1.bn,features.stage2.unit1.body.conv2.conv,features.stage2.unit1.body.conv2.bn,features.stage2.unit1.identity_conv.conv,features.stage2.unit1.identity_conv.bn,features.stage3.unit1.body.conv1.conv,features.stage3.unit1.body.conv1.bn,features.stage3.unit1.body.conv2.conv,features.stage3.unit1.body.conv2.bn,features.stage3.unit1.identity_conv.conv,features.stage3.unit1.identity_conv.bn,features.stage4.unit1.body.conv1.conv,features.stage4.unit1.body.conv1.bn,features.stage4.unit1.body.conv2.conv,features.stage4.unit1.body.conv2.bn,features.stage4.unit1.identity_conv.conv,features.stage4.unit1.identity_conv.bn,output.\n"
     ]
    }
   ],
   "source": [
    "resnet10_in = models.PretrainedResNetForBirdSnap10(\n",
    "    src_dataset='ImageNet1k', arch='ResNet10', n_trainable_layers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty-print layer-by-layer info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================================\n",
       "Layer (type (var_name))                                           Output Shape       Param #\n",
       "=====================================================================================================\n",
       "PretrainedResNetForBirdSnap10 (PretrainedResNetForBirdSnap10)     [1, 10]            --\n",
       "├─ResNet (model)                                                  [1, 10]            --\n",
       "│    └─Sequential (features)                                      [1, 512, 1, 1]     --\n",
       "│    │    └─ResInitBlock (init_block)                             [1, 64, 56, 56]    9,536\n",
       "│    │    └─Sequential (stage1)                                   [1, 64, 56, 56]    73,984\n",
       "│    │    └─Sequential (stage2)                                   [1, 128, 28, 28]   230,144\n",
       "│    │    └─Sequential (stage3)                                   [1, 256, 14, 14]   919,040\n",
       "│    │    └─Sequential (stage4)                                   [1, 512, 7, 7]     3,673,088\n",
       "│    │    └─AvgPool2d (final_pool)                                [1, 512, 1, 1]     --\n",
       "│    └─Linear (output)                                            [1, 10]            5,130\n",
       "=====================================================================================================\n",
       "Total params: 4,910,922\n",
       "Trainable params: 4,910,922\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 888.73\n",
       "=====================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 27.70\n",
       "Params size (MB): 19.64\n",
       "Estimated Total Size (MB): 47.94\n",
       "====================================================================================================="
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(resnet10_in, (1, 3, 224, 224),\n",
    "                  row_settings=['var_names'],\n",
    "                  col_names=[\"output_size\", \"num_params\"],\n",
    "                  col_width=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset BirdsnapDataset\n",
       "    Number of datapoints: 640\n",
       "    Root location: /Users/mhughes/courses/cs152l3d-24f-assignments/hw1/birdsnap10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify data has been extracted correctly and is accessible to load in PyTorch\n",
    "data_utils.BirdsnapDataset(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitname  0  1  2  3  4  5  6  7  8  9\n",
      "    train 40 40 40 40 40 40 40 40 40 40\n",
      "    valid 10 10 10 10 10 10 10 10 10 10\n",
      "     test 14 14 14 14 14 14 14 14 14 14\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = data_utils.make_birdsnap_data_loaders(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 Implementation Tasks\n",
    "\n",
    "In separate windows, you'll need to edit:\n",
    "\n",
    "* models.py, see task (i) here: <https://www.cs.tufts.edu/cs/152L3D/2024f/hw1.html#problem1>\n",
    "* train.py, see tasks (ii, iii, iv) here: <https://www.cs.tufts.edu/cs/152L3D/2024f/hw1.html#problem1>\n",
    "\n",
    "Any edits to these files should *automatically* be reflected here in your active nb session, since we used **autoreload** above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as task (v), complete the implementation of `eval_acc` here to evaluate accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc(model, device, test_loader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            pass # TODO FIXME\n",
    "            # Count number of correct predictions across all batches of provided loader\n",
    "    return correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 Experiments\n",
    "\n",
    "We'll now try to fit models for 2 archs (RN10, RN26) and 2 srcdatasets (ImageNet, CUB)\n",
    "\n",
    "For each one, we'll\n",
    "\n",
    "* keep n_trainable_layers = 1 (\"last layer only\" or \"linear probing\")\n",
    "* Try to find reasonable settings of learning rate (lr), l2 penalty strength (l2pen_mag), and random seed (controls initialization and data order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Last-layer training of ResNet10 from ImageNet1k.**\n",
    "\n",
    "Need to find good hyperparameters (seed, lr, l2penalty magnitude, n_epochs)\n",
    "\n",
    "Don't peek at test, just use validation to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Trainable parameter count=4910922 over 38 tensors in layers: features.init_block.conv.conv,features.init_block.conv.bn,features.stage1.unit1.body.conv1.conv,features.stage1.unit1.body.conv1.bn,features.stage1.unit1.body.conv2.conv,features.stage1.unit1.body.conv2.bn,features.stage2.unit1.body.conv1.conv,features.stage2.unit1.body.conv1.bn,features.stage2.unit1.body.conv2.conv,features.stage2.unit1.body.conv2.bn,features.stage2.unit1.identity_conv.conv,features.stage2.unit1.identity_conv.bn,features.stage3.unit1.body.conv1.conv,features.stage3.unit1.body.conv1.bn,features.stage3.unit1.body.conv2.conv,features.stage3.unit1.body.conv2.bn,features.stage3.unit1.identity_conv.conv,features.stage3.unit1.identity_conv.bn,features.stage4.unit1.body.conv1.conv,features.stage4.unit1.body.conv1.bn,features.stage4.unit1.body.conv2.conv,features.stage4.unit1.body.conv2.bn,features.stage4.unit1.identity_conv.conv,features.stage4.unit1.identity_conv.bn,output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 4/4 [01:24<00:00, 21.20s/it, tr_xent=0.457, tr_err=0.932, va_xent=0, va_err=0.95, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished after epoch 3, best epoch=3\n",
      "best va_xent 0.000\n",
      "best tr_err 0.932\n",
      "best va_err 0.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if PROB1_EXPERIMENTS:\n",
    "    seed = 42\n",
    "    resnet10_in = models.PretrainedResNetForBirdSnap10(\n",
    "        src_dataset='ImageNet1k', arch='ResNet10', n_trainable_layers=1, seed=seed)\n",
    "    best_model, best_info = train.train_model(resnet10_in, device, train_loader, val_loader,\n",
    "        n_epochs=3,\n",
    "        lr=0.001,\n",
    "        l2pen_mag=0, # no L2 penalty on weight magnitude\n",
    "        data_order_seed=seed,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic plot: Error/loss vs epoch\n",
    "\n",
    "The plot below is just a demo of what you can plot. Values won't represent correct operation of model training until you run the code implementation tasks, and start training for longer (adjust n_epochs > 15).\n",
    "\n",
    "FYI: good practices already implemented info dict returned by train_model\n",
    "\n",
    "* Report perf on val on given initial model (epoch=0), before making any updates\n",
    "* Train perf metrics only kick in for epoch 1 and later (when we are doing updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best_info['epochs'], best_info['tr']['loss'], '--', color='b', label='tr loss')\n",
    "plt.plot(best_info['epochs'], best_info['tr']['err'], '-', color='b', label='tr err')\n",
    "\n",
    "plt.plot(best_info['epochs'], best_info['va']['xent'], '--', color='r', label='va xent')\n",
    "plt.plot(best_info['epochs'], best_info['va']['err'], '-', color='r', label='va err')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pro Tip:** Consider storing your \"best\" runs to disk, using code like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if os.path.exists(PROB1_res_file):\n",
    "    with open(PROB1_res_file, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "else:\n",
    "    results = dict()\n",
    "\n",
    "results[(src_dataset, arch)] = best_model, best_info\n",
    "\n",
    "with open(PROB1_res_file, 'w') as f:\n",
    "    f.save(results)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** repeat the above for each config in ('ResNet10', 'ResNet26') and ('ImageNet1k', 'CUB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do tuning expts for Resnet10, CUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do tuning expts for Resnet26, ImageNet1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO do tuning expts for Resnet26, CUB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 Analysis and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy results so we can show what kind of plots we want\n",
    "dummy_result = {}\n",
    "\n",
    "eps = np.arange(20)\n",
    "\n",
    "dummy_result[('ResNet10', 'ImageNet1k')] = dict(\n",
    "    lr = 0.123,\n",
    "    l2pen_mag = 0.0,\n",
    "    seed = 42,\n",
    "    epochs=eps,\n",
    "    tr=dict(\n",
    "        loss=.7 - .3 * (1 - np.abs(eps-10) / 10), # upside-down triangle\n",
    "        xent=.68 - .3 * (1 - np.abs(eps-10) / 10), # upside-down triangle\n",
    "        err=.01 * np.ones(20),\n",
    "    ),\n",
    "    va=dict(\n",
    "        xent=.8 - .2 * (1 - np.abs(eps-10) / 10), # upside-down triangle\n",
    "        err=.1 * np.ones(20),\n",
    "    ),\n",
    "    best_epoch=10,\n",
    "    best_va_loss=0.6,\n",
    ")\n",
    "\n",
    "eps = np.arange(30)\n",
    "dummy_result[('ResNet10', 'CUB')] = dict(\n",
    "    lr = 0.456,\n",
    "    l2pen_mag = 0.0,\n",
    "    seed = 42,\n",
    "    epochs=eps,\n",
    "    tr=dict(\n",
    "        loss=.7 - .3 * (1 - np.abs(eps-15) / 15),  # upside-down triangle\n",
    "        xent=.68 - .3 * (1 - np.abs(eps-15) / 15), # upside-down triangle\n",
    "        err=.01 * np.ones(30),\n",
    "    ),\n",
    "    va=dict(\n",
    "        xent=.9 - .3 * (1 - np.abs(eps-15) / 15), # upside-down triangle\n",
    "        err=.1 * np.ones(30),\n",
    "    ),\n",
    "    best_epoch=15,\n",
    "    best_va_loss=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1a: Loss over Epochs\n",
    "\n",
    "Starter code notebook indicates style of plot desired.\n",
    "\n",
    "**TODO** Your job is to make sure the plot shows your *real* results, not our dummy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axgrid = plt.subplots(nrows=1, ncols=2, figsize=(9,4), sharey=True, sharex=False)\n",
    "\n",
    "for panel_id, (arch, src_dataset) in enumerate([\n",
    "        ('ResNet10','ImageNet1k'),\n",
    "        ('ResNet10','CUB'),\n",
    "        ]):\n",
    "    ax = axgrid[panel_id]\n",
    "    key = (arch, src_dataset)\n",
    "    info = dummy_result[key]\n",
    "    ax.plot(info['epochs'], info['va']['xent'], '--', color='r', label='va xent')\n",
    "    ax.plot(info['epochs'], info['tr']['loss'], '--', color='b', label='tr loss')\n",
    "    ax.plot(info['epochs'], info['va']['err'], label='va err', color='r')\n",
    "    ax.plot(info['epochs'], info['tr']['err'], label='tr err', color='b')\n",
    "    ax.plot(info['best_epoch'], info['best_va_loss'], '*', color='r', markersize=12, label='early stop')\n",
    "    ax.set_xlabel('epoch')\n",
    "    if panel_id == 0:\n",
    "        ax.set_ylabel('loss per example')\n",
    "    lr = info['lr']\n",
    "    l2pen = info['l2pen_mag']\n",
    "    seed = info['seed']\n",
    "    ax.set_title(f'{arch}_{src_dataset}\\nlr={lr}, l2pen={l2pen}, seed={seed}')\n",
    "    ax.set_xlim([-0.001, max(info['epochs'])])\n",
    "\n",
    "ax.set_ylim([0.0, 1.5]);\n",
    "ax.legend(bbox_to_anchor=(1.55, 0.6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1b: Target Acc vs Source Acc\n",
    "\n",
    "**TODO** Lookup source task accuracy (use top1 if needed) from pytorch cv webpage: https://pypi.org/project/pytorchcv/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_acc = {}\n",
    "src_acc[('ResNet10', 'ImageNet1k')] = 0.5 # TODO FIXME\n",
    "src_acc[('ResNet26', 'ImageNet1k')] = 0.9 # TODO FIXME\n",
    "\n",
    "src_acc[('ResNet10', 'CUB')] = 0.5 # TODO FIXME\n",
    "src_acc[('ResNet26', 'CUB')] = 0.9 # TODO FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Measure your best model accuracy using provided test_loader and `eval_acc` function, record values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_acc = {}\n",
    "tar_acc[('ResNet10', 'ImageNet1k')] = 0.5 # TODO FIXME\n",
    "tar_acc[('ResNet26', 'ImageNet1k')] = 0.9 # TODO FIXME\n",
    "\n",
    "tar_acc[('ResNet10', 'CUB')] = 0.5 # TODO FIXME\n",
    "tar_acc[('ResNet26', 'CUB')] = 0.9 # TODO FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axgrid = plt.subplots(nrows=1, ncols=2, figsize=(9,4), sharey=True)\n",
    "\n",
    "arch_list = ['ResNet10', 'ResNet26']\n",
    "srcdata_list = ['ImageNet1k', 'CUB']\n",
    "\n",
    "for (arch, src_dataset) in itertools.product(arch_list, srcdata_list):\n",
    "    if src_dataset.count(\"ImageNet\"):\n",
    "        panel_id = 0\n",
    "    else:\n",
    "        panel_id = 1\n",
    "    ax = axgrid[panel_id]\n",
    "    ax.set_title(\"pretrain on \" + src_dataset)\n",
    "    key = \"{arch}_{src_dataset}\".format(arch=arch, src_dataset=src_dataset)\n",
    "    cur_target_acc = tar_acc[(arch, src_dataset)]\n",
    "    cur_src_acc = src_acc[(arch, src_dataset)]\n",
    "    ax.plot(cur_src_acc, cur_target_acc, 'v' if arch.count('10') else '^', label=arch, markersize=12)\n",
    "    ax.set_xlim([0.25, 1.0]); ax.set_xticks([.4, .6, .8, 1]);\n",
    "    ax.set_ylim([0.25, 1.0]); ax.set_yticks([.4, .6, .8, 1]);\n",
    "    ax.set_xlabel(f\"acc on {src_dataset}\");\n",
    "    if panel_id == 0:\n",
    "        ax.set_ylabel(f\"LP acc on BirdSnap10\");\n",
    "plt.legend(bbox_to_anchor=(1.55, 0.6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Implement LP-then-FT, via repeated calls to **train_model**\n",
    "\n",
    "* LP phase should use n_trainable_layers=1 (about 5000 trainable params)\n",
    "* FT phase should use n_trainable_layers=3 (about 100000 trainable params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.arange(20)\n",
    "\n",
    "P2_dummy_result = {}\n",
    "\n",
    "# Phase 1, copy hard work from Problem 1\n",
    "P2_dummy_result[('ResNet10', 'ImageNet1k','phase1')] = dummy_result[('ResNet10', 'ImageNet1k')]\n",
    "\n",
    "eps = np.arange(20)\n",
    "P2_dummy_result[('ResNet10', 'ImageNet1k','phase2')] = dict(\n",
    "    lr = 0.456,\n",
    "    l2pen_mag = 0.0,\n",
    "    seed = 42,\n",
    "    epochs=np.arange(20),\n",
    "    tr=dict(\n",
    "        loss=.3 - 0.15 * (eps/max(eps)),\n",
    "        err=.01 * np.ones(20),\n",
    "    ),\n",
    "    va=dict(\n",
    "        xent=.6 - 0.15 * (eps/max(eps)),\n",
    "        err=.1 * np.ones(20),\n",
    "    ),\n",
    "    best_epoch=10,\n",
    "    best_va_loss=0.6,\n",
    "    test_acc=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2a: Trace plots for LP then FT\n",
    "\n",
    "We'll be looking for:\n",
    "\n",
    "* Clear continuity in val set perf (the FT phase started at val set err rate/xent of the best LP checkpoint)\n",
    "* Some kind of improvement in the FT phase, at least on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axgrid = plt.subplots(nrows=1, ncols=2, figsize=(9,4), sharey=True)\n",
    "\n",
    "LPbest = P2_dummy_result[('ResNet10', 'ImageNet1k', 'phase1')]\n",
    "FTbest = P2_dummy_result[('ResNet10', 'ImageNet1k', 'phase2')]\n",
    "\n",
    "# Only show LP phase until early stop occurs\n",
    "eps = [e for e in LPbest['epochs'] if e <= LPbest['best_epoch']]\n",
    "axgrid[0].plot(eps, LPbest['va']['xent'][:len(eps)], '--', color='r', label='val xent')\n",
    "axgrid[0].plot(eps, LPbest['tr']['loss'][:len(eps)], '--', color='b')\n",
    "axgrid[0].plot(eps, LPbest['va']['err'][:len(eps)], color='r', label='val')\n",
    "axgrid[0].plot(eps, LPbest['tr']['err'][:len(eps)], '-', color='b')\n",
    "axgrid[0].plot(LPbest['best_epoch'], LPbest['best_va_loss'], '*', color='r', markersize=12);\n",
    "axgrid[0].set_title(\"Phase 1: LP\");\n",
    "axgrid[0].set_xlabel(\"LP epochs\");\n",
    "axgrid[0].set_ylabel(\"loss\");\n",
    "\n",
    "FTeps = FTbest['epochs']\n",
    "axgrid[1].plot(FTeps, FTbest['va']['xent'], '--', color='r', label='val xent')\n",
    "axgrid[1].plot(FTeps, FTbest['tr']['loss'], '--', color='b', label='tr loss')\n",
    "axgrid[1].plot(FTeps, FTbest['va']['err'], '-', color='r', label='val err')\n",
    "axgrid[1].plot(FTeps, FTbest['tr']['err'], '-', color='b', label='tr err')\n",
    "axgrid[1].set_title(\"Phase 2: FT\");\n",
    "axgrid[1].set_ylim([-0.02, 1.]);\n",
    "axgrid[1].set_xlabel('FT epochs');\n",
    "axgrid[1].legend(loc='upper right');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2b: Report test-set acc for both the phase1 and phase 2\n",
    "\n",
    "These numbers will be presented in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute test acc after the LP phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute test acc after the FT-3 phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
